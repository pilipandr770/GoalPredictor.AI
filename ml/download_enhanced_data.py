"""
–ó–∞–≥—Ä—É–∑–∫–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å Kaggle —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π –º–∞—Ç—á–µ–π
–î–∞—Ç–∞—Å–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç —É–¥–∞—Ä—ã, –∫–æ—Ä–Ω–µ—Ä—ã, —Ñ–æ–ª—ã, –≤–ª–∞–¥–µ–Ω–∏–µ –º—è—á–æ–º –∏ –º–Ω–æ–≥–æ–µ –¥—Ä—É–≥–æ–µ
"""
import kagglehub
import pandas as pd
import os
from pathlib import Path
import shutil


class EnhancedKaggleDataLoader:
    """–ó–∞–≥—Ä—É–∑—á–∏–∫ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏"""
    
    def __init__(self):
        self.data_dir = Path('data')
        self.raw_dir = self.data_dir / 'raw'
        self.processed_dir = self.data_dir / 'processed'
        
        # –°–æ–∑–¥–∞—Ç—å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        self.raw_dir.mkdir(parents=True, exist_ok=True)
        self.processed_dir.mkdir(parents=True, exist_ok=True)
    
    def download_european_football_dataset(self):
        """
        –ó–∞–≥—Ä—É–∑–∏—Ç—å –±–æ–ª—å—à–æ–π –¥–∞—Ç–∞—Å–µ—Ç –µ–≤—Ä–æ–ø–µ–π—Å–∫–æ–≥–æ —Ñ—É—Ç–±–æ–ª–∞
        –°–æ–¥–µ—Ä–∂–∏—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∑–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∑–æ–Ω–æ–≤ —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
        """
        print("üì• –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ –µ–≤—Ä–æ–ø–µ–π—Å–∫–æ–≥–æ —Ñ—É—Ç–±–æ–ª–∞...")
        print("   –î–∞—Ç–∞—Å–µ—Ç: hugomathien/soccer")
        
        try:
            # –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç —Å Kaggle
            path = kagglehub.dataset_download("hugomathien/soccer")
            print(f"‚úÖ –î–∞—Ç–∞—Å–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω: {path}")
            
            # –ù–∞–π—Ç–∏ —Ñ–∞–π–ª database.sqlite
            dataset_path = Path(path)
            sqlite_file = None
            
            for file in dataset_path.rglob("*.sqlite"):
                sqlite_file = file
                break
            
            if sqlite_file:
                print(f"üìÇ –ù–∞–π–¥–µ–Ω —Ñ–∞–π–ª: {sqlite_file}")
                
                # –°–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –≤ –Ω–∞—à—É –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
                target_path = self.raw_dir / "european_football.sqlite"
                shutil.copy2(sqlite_file, target_path)
                print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: {target_path}")
                
                return str(target_path)
            else:
                print("‚ùå SQLite —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω!")
                return None
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
            return None
    
    def download_football_data_europe(self):
        """
        –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç football-data.co.uk —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
        –°–æ–¥–µ—Ä–∂–∏—Ç —É–¥–∞—Ä—ã, –∫–æ—Ä–Ω–µ—Ä—ã, –∫–∞—Ä—Ç–æ—á–∫–∏, –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –±—É–∫–º–µ–∫–µ—Ä–æ–≤
        """
        print("\nüì• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ Football-Data.co.uk...")
        print("   –î–∞—Ç–∞—Å–µ—Ç: saife245/english-premier-league")
        
        try:
            path = kagglehub.dataset_download("saife245/english-premier-league")
            print(f"‚úÖ –î–∞—Ç–∞—Å–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω: {path}")
            
            # –ù–∞–π—Ç–∏ CSV —Ñ–∞–π–ª—ã
            dataset_path = Path(path)
            csv_files = list(dataset_path.rglob("*.csv"))
            
            if csv_files:
                print(f"üìÇ –ù–∞–π–¥–µ–Ω–æ CSV —Ñ–∞–π–ª–æ–≤: {len(csv_files)}")
                
                # –û–±—ä–µ–¥–∏–Ω–∏—Ç—å –≤—Å–µ CSV –≤ –æ–¥–∏–Ω DataFrame
                all_data = []
                for csv_file in csv_files:
                    try:
                        df = pd.read_csv(csv_file, encoding='utf-8')
                        all_data.append(df)
                        print(f"   ‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {csv_file.name} ({len(df)} –º–∞—Ç—á–µ–π)")
                    except Exception as e:
                        print(f"   ‚úó –û—à–∏–±–∫–∞ –≤ {csv_file.name}: {e}")
                
                if all_data:
                    combined_df = pd.concat(all_data, ignore_index=True)
                    
                    # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å
                    target_path = self.raw_dir / "premier_league_detailed.csv"
                    combined_df.to_csv(target_path, index=False)
                    print(f"üíæ –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {target_path}")
                    print(f"   –í—Å–µ–≥–æ –º–∞—Ç—á–µ–π: {len(combined_df)}")
                    print(f"   –ö–æ–ª–æ–Ω–æ–∫: {len(combined_df.columns)}")
                    
                    return str(target_path)
            
            return None
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
            return None
    
    def download_all_european_leagues(self):
        """
        –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç —Å–æ –≤—Å–µ–º–∏ –µ–≤—Ä–æ–ø–µ–π—Å–∫–∏–º–∏ –ª–∏–≥–∞–º–∏
        –°–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ø-5 –ª–∏–≥ –∑–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∑–æ–Ω–æ–≤
        """
        print("\nüì• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –≤—Å–µ—Ö –µ–≤—Ä–æ–ø–µ–π—Å–∫–∏—Ö –ª–∏–≥...")
        print("   –î–∞—Ç–∞—Å–µ—Ç: sanjeetsinghnaik/most-recent-soccer-scores-stats")
        
        try:
            path = kagglehub.dataset_download("sanjeetsinghnaik/most-recent-soccer-scores-stats")
            print(f"‚úÖ –î–∞—Ç–∞—Å–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω: {path}")
            
            # –ù–∞–π—Ç–∏ CSV —Ñ–∞–π–ª—ã
            dataset_path = Path(path)
            csv_files = list(dataset_path.rglob("*.csv"))
            
            if csv_files:
                print(f"üìÇ –ù–∞–π–¥–µ–Ω–æ CSV —Ñ–∞–π–ª–æ–≤: {len(csv_files)}")
                
                all_data = []
                for csv_file in csv_files:
                    try:
                        df = pd.read_csv(csv_file, encoding='utf-8', on_bad_lines='skip')
                        if len(df) > 0:
                            all_data.append(df)
                            print(f"   ‚úì {csv_file.name}: {len(df)} –º–∞—Ç—á–µ–π")
                    except Exception as e:
                        print(f"   ‚úó –û—à–∏–±–∫–∞: {e}")
                
                if all_data:
                    combined_df = pd.concat(all_data, ignore_index=True)
                    target_path = self.raw_dir / "all_european_leagues.csv"
                    combined_df.to_csv(target_path, index=False)
                    print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {target_path}")
                    print(f"   –í—Å–µ–≥–æ –º–∞—Ç—á–µ–π: {len(combined_df)}")
                    
                    return str(target_path)
            
            return None
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            return None
    
    def load_and_analyze_dataset(self, filepath):
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –∏ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –¥–∞—Ç–∞—Å–µ—Ç"""
        print(f"\nüìä –ê–Ω–∞–ª–∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞: {filepath}")
        
        try:
            df = pd.read_csv(filepath, on_bad_lines='skip')
            
            print(f"\n‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ:")
            print(f"   –°—Ç—Ä–æ–∫: {len(df)}")
            print(f"   –ö–æ–ª–æ–Ω–æ–∫: {len(df.columns)}")
            
            print(f"\nüìã –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏:")
            for i, col in enumerate(df.columns, 1):
                non_null = df[col].notna().sum()
                percent = (non_null / len(df)) * 100
                print(f"   {i:2}. {col:30} - {non_null:6} –∑–Ω–∞—á–µ–Ω–∏–π ({percent:.1f}%)")
            
            print(f"\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
            print(df.describe())
            
            print(f"\nüîç –ü–µ—Ä–≤—ã–µ 3 —Å—Ç—Ä–æ–∫–∏:")
            print(df.head(3))
            
            return df
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
            return None


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤"""
    print("="*70)
    print("üöÄ –ó–ê–ì–†–£–ó–ö–ê –†–ê–°–®–ò–†–ï–ù–ù–´–• –î–ê–¢–ê–°–ï–¢–û–í –î–õ–Ø –£–õ–£–ß–®–ï–ù–ò–Ø –ú–û–î–ï–õ–ò")
    print("="*70)
    
    loader = EnhancedKaggleDataLoader()
    
    # –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ä–∞–∑–Ω—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã
    datasets = []
    
    # 1. Premier League —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
    print("\n" + "="*70)
    print("–î–ê–¢–ê–°–ï–¢ 1: PREMIER LEAGUE –° –î–ï–¢–ê–õ–¨–ù–û–ô –°–¢–ê–¢–ò–°–¢–ò–ö–û–ô")
    print("="*70)
    path1 = loader.download_football_data_europe()
    if path1:
        df1 = loader.load_and_analyze_dataset(path1)
        if df1 is not None:
            datasets.append(('premier_league_detailed', df1))
    
    # 2. –í—Å–µ –µ–≤—Ä–æ–ø–µ–π—Å–∫–∏–µ –ª–∏–≥–∏
    print("\n" + "="*70)
    print("–î–ê–¢–ê–°–ï–¢ 2: –í–°–ï –ï–í–†–û–ü–ï–ô–°–ö–ò–ï –õ–ò–ì–ò")
    print("="*70)
    path2 = loader.download_all_european_leagues()
    if path2:
        df2 = loader.load_and_analyze_dataset(path2)
        if df2 is not None:
            datasets.append(('all_european_leagues', df2))
    
    # 3. –ï–≤—Ä–æ–ø–µ–π—Å–∫–∏–π —Ñ—É—Ç–±–æ–ª (SQLite –±–∞–∑–∞)
    print("\n" + "="*70)
    print("–î–ê–¢–ê–°–ï–¢ 3: EUROPEAN FOOTBALL DATABASE")
    print("="*70)
    path3 = loader.download_european_football_dataset()
    if path3:
        print("‚úÖ SQLite –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
        print("   –î–ª—è —Ä–∞–±–æ—Ç—ã —Å –Ω–µ–π –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ sqlite3 –±–∏–±–ª–∏–æ—Ç–µ–∫—É")
    
    # –ò—Ç–æ–≥–∏
    print("\n" + "="*70)
    print("üìä –ò–¢–û–ì–ò –ó–ê–ì–†–£–ó–ö–ò")
    print("="*70)
    print(f"–£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤: {len(datasets)}")
    for name, df in datasets:
        print(f"  ‚úì {name}: {len(df)} –º–∞—Ç—á–µ–π, {len(df.columns)} –∫–æ–ª–æ–Ω–æ–∫")
    
    if datasets:
        print("\n‚úÖ –î–∞—Ç–∞—Å–µ—Ç—ã –≥–æ—Ç–æ–≤—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —É–ª—É—á—à–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π!")
    else:
        print("\n‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–∏ –æ–¥–∏–Ω –¥–∞—Ç–∞—Å–µ—Ç.")
        print("    –ë—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –¥–∞—Ç–∞—Å–µ—Ç.")
    
    return datasets


if __name__ == '__main__':
    main()
