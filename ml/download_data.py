"""
–°–∫—Ä–∏–ø—Ç –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö —Å Kaggle
–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç —Å —Ñ—É—Ç–±–æ–ª—å–Ω—ã–º–∏ –º–∞—Ç—á–∞–º–∏ —Ç–æ–ø-5 –ª–∏–≥ (2024-2025)
"""
import os
import kagglehub
import pandas as pd
import shutil
from pathlib import Path


class KaggleDataLoader:
    """
    –ó–∞–≥—Ä—É–∑—á–∏–∫ –¥–∞–Ω–Ω—ã—Ö —Å Kaggle
    """
    
    def __init__(self):
        self.dataset_name = "tarekmasryo/football-matches-20242025-top-5-leagues"
        self.data_dir = Path("data")
        self.raw_dir = self.data_dir / "raw"
        self.processed_dir = self.data_dir / "processed"
        
        # –°–æ–∑–¥–∞—Ç—å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        self.data_dir.mkdir(exist_ok=True)
        self.raw_dir.mkdir(exist_ok=True)
        self.processed_dir.mkdir(exist_ok=True)
    
    def download_dataset(self):
        """
        –°–∫–∞—á–∞—Ç—å –¥–∞—Ç–∞—Å–µ—Ç —Å Kaggle
        """
        print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å Kaggle...")
        print(f"   –î–∞—Ç–∞—Å–µ—Ç: {self.dataset_name}")
        
        try:
            # –°–∫–∞—á–∞—Ç—å –¥–∞—Ç–∞—Å–µ—Ç
            path = kagglehub.dataset_download(self.dataset_name)
            print(f"‚úÖ –î–∞—Ç–∞—Å–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω –≤: {path}")
            
            # –°–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å —Ñ–∞–π–ª—ã –≤ data/raw
            self._copy_files(path)
            
            return path
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞: {e}")
            print("\n‚ö†Ô∏è  –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ:")
            print("   1. –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω kagglehub: pip install kagglehub")
            print("   2. –ù–∞—Å—Ç—Ä–æ–µ–Ω Kaggle API: https://www.kaggle.com/docs/api")
            print("   3. –§–∞–π–ª kaggle.json –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ ~/.kaggle/")
            return None
    
    def _copy_files(self, source_path):
        """
        –°–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å —Ñ–∞–π–ª—ã –∏–∑ –∫–µ—à–∞ Kaggle –≤ data/raw
        """
        print("üìÇ –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ –≤ data/raw...")
        
        source = Path(source_path)
        
        # –ù–∞–π—Ç–∏ –≤—Å–µ CSV —Ñ–∞–π–ª—ã
        csv_files = list(source.glob("*.csv"))
        
        if not csv_files:
            # –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –Ω–∞–π—Ç–∏ –≤ –ø–æ–¥–ø–∞–ø–∫–∞—Ö
            csv_files = list(source.rglob("*.csv"))
        
        if csv_files:
            for csv_file in csv_files:
                dest = self.raw_dir / csv_file.name
                shutil.copy2(csv_file, dest)
                print(f"   ‚úÖ {csv_file.name} ‚Üí data/raw/")
        else:
            print("   ‚ö†Ô∏è  CSV —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
    
    def load_data(self):
        """
        –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ CSV —Ñ–∞–π–ª–æ–≤
        """
        print("\nüìä –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
        
        csv_files = list(self.raw_dir.glob("*.csv"))
        
        if not csv_files:
            print("‚ùå CSV —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ data/raw/")
            print("   –ó–∞–ø—É—Å—Ç–∏—Ç–µ download_dataset() —Å–Ω–∞—á–∞–ª–∞")
            return None
        
        # –ó–∞–≥—Ä—É–∑–∏—Ç—å –≤—Å–µ CSV —Ñ–∞–π–ª—ã
        dataframes = []
        
        for csv_file in csv_files:
            print(f"   üìÑ –ó–∞–≥—Ä—É–∑–∫–∞ {csv_file.name}...")
            try:
                df = pd.read_csv(csv_file)
                dataframes.append(df)
                print(f"      ‚úÖ {len(df)} —Å—Ç—Ä–æ–∫, {len(df.columns)} —Å—Ç–æ–ª–±—Ü–æ–≤")
            except Exception as e:
                print(f"      ‚ùå –û—à–∏–±–∫–∞: {e}")
        
        if not dataframes:
            return None
        
        # –û–±—ä–µ–¥–∏–Ω–∏—Ç—å –≤—Å–µ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º—ã
        if len(dataframes) == 1:
            combined_df = dataframes[0]
        else:
            print("\nüîó –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–æ–≤...")
            combined_df = pd.concat(dataframes, ignore_index=True)
        
        print(f"\n‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –≤—Å–µ–≥–æ: {len(combined_df)} –º–∞—Ç—á–µ–π")
        print(f"   –°—Ç–æ–ª–±—Ü—ã: {', '.join(combined_df.columns[:10])}...")
        
        return combined_df
    
    def prepare_training_data(self, df):
        """
        –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
        """
        print("\nüîß –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è...")
        
        # –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        print(f"   –†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞: {df.shape}")
        print(f"   –°—Ç–æ–ª–±—Ü—ã: {list(df.columns)}")
        
        # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤
        required_columns = ['Date', 'HomeTeam', 'AwayTeam']
        missing = [col for col in required_columns if col not in df.columns]
        
        if missing:
            print(f"\n‚ö†Ô∏è  –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Å—Ç–æ–ª–±—Ü—ã: {missing}")
            print("   –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è...")
            
            # –ü–æ–∫–∞–∑–∞—Ç—å –≤—Å–µ —Å—Ç–æ–ª–±—Ü—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            print(f"\n   –î–æ—Å—Ç—É–ø–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã:")
            for i, col in enumerate(df.columns, 1):
                print(f"      {i}. {col}")
        
        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        output_file = self.processed_dir / "football_matches.csv"
        df.to_csv(output_file, index=False)
        print(f"\n‚úÖ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_file}")
        
        return df
    
    def get_dataset_info(self, df):
        """
        –ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–∞—Ç–∞—Å–µ—Ç–µ
        """
        print("\nüìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞—Ç–∞—Å–µ—Ç–µ:")
        print(f"   –í—Å–µ–≥–æ –º–∞—Ç—á–µ–π: {len(df)}")
        print(f"   –°—Ç–æ–ª–±—Ü–æ–≤: {len(df.columns)}")
        print(f"   –ü–∞–º—è—Ç–∏: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")
        
        # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        missing = df.isnull().sum()
        if missing.sum() > 0:
            print(f"\n   ‚ö†Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è:")
            for col, count in missing[missing > 0].items():
                print(f"      {col}: {count} ({count/len(df)*100:.1f}%)")
        
        # –ü–æ–∫–∞–∑–∞—Ç—å –ø—Ä–∏–º–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö
        print(f"\n   –ü—Ä–∏–º–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö:")
        print(df.head(3).to_string())
        
        return df.describe()


def main():
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö
    """
    print("‚öΩ GoalPredictor.AI - –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å Kaggle\n")
    
    loader = KaggleDataLoader()
    
    # –®–∞–≥ 1: –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç
    path = loader.download_dataset()
    
    if path is None:
        print("\n‚ùå –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å")
        return
    
    # –®–∞–≥ 2: –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –≤ DataFrame
    df = loader.load_data()
    
    if df is None:
        print("\n‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ")
        return
    
    # –®–∞–≥ 3: –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ
    df = loader.prepare_training_data(df)
    
    # –®–∞–≥ 4: –ü–æ–∫–∞–∑–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
    loader.get_dataset_info(df)
    
    print("\nüéâ –ì–æ—Ç–æ–≤–æ! –î–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏")
    print(f"   –§–∞–π–ª: data/processed/football_matches.csv")
    print(f"\n   –°–ª–µ–¥—É—é—â–∏–π —à–∞–≥: python ml/train.py")


if __name__ == "__main__":
    main()
